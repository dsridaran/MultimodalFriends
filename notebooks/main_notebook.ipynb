{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "119ec496-64a9-48f7-a1d2-f5611c190cd4",
   "metadata": {},
   "source": [
    "## Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "285173aa-5836-4103-ab34-7f185b4cf741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.data.preprocess import load_text_data, load_image_data, attach_image_data, save_preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950833b0-e97c-4d10-bd54-8e4c8afddcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to your text and image data\n",
    "text_data_paths = ['../data/raw/train_sent_emo.csv', '../data/raw/dev_sent_emo.csv', '../data/raw/test_sent_emo.csv']\n",
    "image_data_paths = ['../data/raw/train.pkl', '../data/raw/dev.pkl', '../data/raw/test.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105cd955-1fef-4b54-afcc-178556f22752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess text data\n",
    "train_df, dev_df, test_df = load_and_preprocess_data(text_data_paths)\n",
    "\n",
    "# Load image data\n",
    "image_data = [load_image_data(path) for path in image_data_paths]\n",
    "\n",
    "# Attach image data to your DataFrames\n",
    "text_data_frames = [train_df, dev_df, test_df]\n",
    "text_data_frames = attach_image_data(text_data_frames, image_data)\n",
    "train_df, dev_df, test_df = text_data_frames\n",
    "\n",
    "# Save the preprocessed data (optional)\n",
    "save_paths = ['../data/processed/train_full.pkl', '../data/processed/dev_full.pkl', '../data/processed/test_full.pkl']\n",
    "save_preprocessed_data(text_data_frames, save_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a25328d-4559-4d8d-b730-799aeb301970",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25f2eac1-838b-41d9-9ca1-b30e19f7c980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.train_model import train_text_only_model, train_image_only_model, train_multi_modal_model\n",
    "from src.models.evaluate_model import evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9ef394-e90a-4fe8-802c-91a23efb368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform target into dummy vector\n",
    "y_train = pd.get_dummies(train_df['Emotion']).to_numpy()\n",
    "y_dev = pd.get_dummies(dev_df['Emotion']).to_numpy()\n",
    "y_test = pd.get_dummies(test_df['Emotion']).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09fc288-e836-4caf-9dc2-4c4dfef9c604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define BERT pre-preprocessing\n",
    "bert_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
    "\n",
    "# Define BERT encoder\n",
    "bert_layers = 12\n",
    "bert_units = 768\n",
    "bert_heads = 12\n",
    "bert_encoder = f'https://tfhub.dev/tensorflow/bert_en_uncased_L-{bert_layers}_H-{bert_units}_A-{bert_heads}/4'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd6545f-bfcc-4add-a3ca-17a435b7dfbc",
   "metadata": {},
   "source": [
    "### Text-only Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c53c8a1-874e-4ab8-a6c7-d578696e9c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify text features\n",
    "X_train = train_df['input']\n",
    "X_test = test_df['input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fe6133-b449-40a0-aa64-2f2ef360004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "text_model = train_text_only_model(X_train, y_train, bert_preprocess, bert_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e27b3d9-b800-4c70-861f-caa852ab46a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "accuracy, f1, conf_matrix = evaluate_model(text_model, X_test, y_test)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8313ae7d-cb70-49c9-a4c7-3cea0bf1bf09",
   "metadata": {},
   "source": [
    "### Image-only Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0faf79-a0ff-42e2-8eab-aa750335be01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify image features\n",
    "X_train = np.array([np.concatenate([np.array(row['first_frame']), np.array(row['middle_frame']), np.array(row['last_frame'])]) for index, row in train_df.iterrows()])\n",
    "X_test = np.array([np.concatenate([np.array(row['first_frame']), np.array(row['middle_frame']), np.array(row['last_frame'])]) for index, row in test_df.iterrows()])\n",
    "\n",
    "# Scale image features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a72b57-d14c-4bc1-a067-458d0bfa8760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "image_model = train_image_only_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff9a93a-2fb8-48d2-88a4-9c417ff848ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "accuracy, f1, conf_matrix = evaluate_model(image_model, X_test, y_test)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c94bcfc-b37f-4856-9b1a-13ee8d17a2bf",
   "metadata": {},
   "source": [
    "### Multi-modal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e1d0f3-6a89-4ef5-b518-7a6bce28d9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify text features\n",
    "X_train_text = train_df['input']\n",
    "X_test_text = test_df['input']\n",
    "\n",
    "# Identify image features\n",
    "X_train_image = np.array([np.concatenate([np.array(row['first_frame']), np.array(row['middle_frame']), np.array(row['last_frame'])]) for index, row in train_df.iterrows()])\n",
    "X_test_image = np.array([np.concatenate([np.array(row['first_frame']), np.array(row['middle_frame']), np.array(row['last_frame'])]) for index, row in test_df.iterrows()])\n",
    "\n",
    "# Scale image features\n",
    "scaler = StandardScaler()\n",
    "X_train_image = scaler.fit_transform(X_train_image)\n",
    "X_test_image = scaler.transform(X_test_image)\n",
    "\n",
    "# Concatenate features\n",
    "X_train = [X_train_text, X_train_image]\n",
    "X_test = [X_test_text, X_test_image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc8471a-0760-40a9-832f-649bae88044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "multi_modal_model = train_multi_modal_model(X_train, y_train, bert_preprocess, bert_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41173a19-0092-4274-87fb-22414f27cf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "accuracy, f1, conf_matrix = evaluate_model(multi_modal_model, X_test, y_test)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
